<!--
This file is part of BenchExec, a framework for reliable benchmarking:
https://github.com/sosy-lab/benchexec

SPDX-FileCopyrightText: 2021 Dirk Beyer <https://www.sosy-lab.org>
SPDX-FileCopyrightText: 2024 Levente Bajczi
SPDX-FileCopyrightText: Critical Systems Research Group
SPDX-FileCopyrightText: Budapest University of Technology and Economics <https://www.ftsrg.mit.bme.hu>

SPDX-License-Identifier: Apache-2.0
-->
# BenchExec Extension for Benchmarking via SLURM

> [!IMPORTANT]  
> The previous, single-job-based SLURM integration is no longer maintained. For its documentation, see [README-old.md](./README-old.md)

This Python script extends BenchExec, a benchmarking framework, to facilitate benchmarking via SLURM array jobs using Singularity containers.

In case of problems, please tag in an [issue](https://github.com/sosy-lab/benchexec/issues/new/choose): [Levente Bajczi](https://github.com/leventeBajczi) (@leventeBajczi).

## Preliminaries

* [SLURM](https://slurm.schedmd.com/documentation.html) is an open-source job scheduling and workload management system used primarily in high-performance computing (HPC) environments.
* [Singularity](https://docs.sylabs.io/guides/latest/user-guide/) is a containerization platform designed for scientific and high-performance computing (HPC) workloads, providing users with a reproducible and portable environment for running applications and workflows.

## Requirements

* SLURM, tested with `slurm 22.05.7`, should work within `22.x.x`
* Singularity, tested with `singularity-ce version 4.0.1`, should work within `4.x.x`
* cgroup support is required 

## Usage
1. Run the script with Python 3:
   ```
   python3 $BENCHEXEC_FOLDER/contrib/slurm-benchmark.py [options]
   ```
   Options:
   - `--slurm-array`: Use SLURM array jobs to execute benchmarks. Will revert to regular (local) benchexec if not given.
   - `--singularity <path_to_sif>`: Specify the path to the Singularity .sif file to use. See usage later.
   - `--scratchdir <path>`: Specify the directory for temporary files. The script will use this parameter to create temporary directories for file storage per-run, which get discarded later. By default, this is the CWD, which might result in temporary files being generated by the thousands in the working directory. On some systems, this must be on the same mount, or even under the same hierarchy as the current directory. Must exist, be writable, and be a directory.
   - `--retry-killed <N>`: Retry killed jobs (e.g., due to SLURM errors) this many times. Use -1 for unbounded retry attempts.
   - `-N <N>`: Specify the factor of parallelism, i.e., how many jobs to submit at a time. Tested with up to `1000`, probably works with much higher values as well.
   - `--aggregation-factor`: Put this many jobs into a single job of the array. 
   - `--batch-size`: Allow this many runs inside a runcollection to be submitted. Lower values might hurt responsiveness, higher values might cause problems with script sizes. Suggested size is around a few thousand.
   - `--parallelization`: Execute this many jobs in parallel inside a job of the array.
    
## Overview of the Workflow

This works similarly to BenchExec, however, instead of delegating each run directly to `runexec`, it creates a hierarchy of run infos and an array job description for SLURM, which is then executed using `sbatch`. `runexec` is still used to measure and limit resources.

1. The script wraps the command to run in a container. This is useful for dependency management (in most HPC environments, arbitrary package installations are frowned upon). For a simple container, use the following: 

    ```singularity
      BootStrap: docker
      From: ubuntu:24.04
      
      %post
      apt -y update
      apt -y install <necessary packages for the tools>
      apt -y install software-properties-common
      add-apt-repository ppa:sosy-lab/benchmarking
      apt -y install benchexec fuse-overlayfs
      mkdir /work
      mkdir /upper
    ```
   
    Use `singularity build [--remote / --fakeroot] --fix-perms <name>.sif <name>.def` to build the container. A remote service (e.g., [sylabs](https://cloud.sylabs.io/builder)) may be used if root permissions are missing.
    
    Notice the `fuse-overlayfs` and `benchexec` packages. That is mandatory for the overlay filesystem to work properly and for `runexec` to exist in the container. 
    
    The script parameterizes `singularity exec` with the following params:
    * `-B "/sys/fs/cgroup:/sys/fs/cgroup"`: Bind the cgroup hierarchy for use inside the container
    * `-B {basedir}`: Bind the "base directory" (directory of the .sif file) (can be read-only)
    * `-B {workdir}:/lower`: Bind the current directory to `/lower` (can be read-only)
    * `--no-home`: Do not bind the home directory
    * `-B {tempdir}:/overlay`: Bind the temporary directory to `/overlay` (must be writeable)
    * `--fusemount  "container:fuse-overlayfs -o lowerdir=/lower -o upperdir=/overlay/upper -o workdir=/overlay/work {workdir}"`: mount an overlay filesystem at {workdir} under {basedir}, where modifications go in the temp dir

2. A `--batch-size`-sized portion of the runs is organized into bins of size `--aggregation-factor`. Each bin will correspond to a job in the array. Inside each bin, `--parallelization`-many `runexec` instances can be started with exact resource allocations and usage reporting. Output files and output log are stored inside the temp dir. If an error is encountered (most commonly this is due to `fuse` locking up and causing a TIMEOUT without any logs being ready) the run is put into a second-chance queue to be run again, at most `--retry-killed` times. 

3. The script parses the resource usage and status of each run, as it would with regular `runexec`. 

## Limitations

Currently, there are the following limitations compared to local benchexec:

1. No exotic paths in the command are handled: only the directory of the `.sif` file and its children are visible in the container.
1. The executor only works with hyperthreading disabled, due to the inability to query nodes about the number of threads per core. Assuming it's always 2 is risky, as it may not hold true universally. Consequently, because we can only request whole cores from SLURM instead of threads, we must divide the requested number of threads by the threads-per-core value, which is unknown if hyperthreading could be enabled.
1. `fuse` sometimes locks up (more precisely: is in an uninterruptible state) for the entire duration of a job. My guess is the underlying lustre file system does not like it when the same path is overlayed from hundreds of nodes at the same time. As a mitigation, we re-run timed out jobs (not runs!).